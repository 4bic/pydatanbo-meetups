{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><b>\n",
    "Data Collection from websites\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access Houses in NBO webpage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://house.jumia.co.ke/for-sale/\")\n",
    "c = r.content\n",
    "soup = BeautifulSoup(c, \"html.parser\")\n",
    "# check source code of loaded page\n",
    "# print(soup.prettify())\n",
    "\n",
    "# # extract division\n",
    "all = soup.find_all(\"div\",{\"class\":\"listing-info\"})\n",
    "len(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check  price element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = all[0].find(\"span\",{\"class\":\"listing-price\"}).text.replace(\",\", \"\")\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection \n",
    "\n",
    "        - Crawl web pages \n",
    "        - Extract selected elements \n",
    "        - Colect dict and store in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://house.jumia.co.ke/nairobi/house/for-sale/?page=\"\n",
    "data = []\n",
    "#   crawl though available pages to extract page no. links\n",
    "for page in range(1,51,1): #used 51 since its the last page\n",
    "    prop_page = base_url+str(page)+str(\"&size=30\")\n",
    "    r = requests.get(prop_page)\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"html.parser\")\n",
    "    all = soup.find_all(\"div\",{\"class\":\"listing-info\"})\n",
    "    # collect price, detail and size from each page\n",
    "    for item in all:\n",
    "        d={}\n",
    "    #  property value\n",
    "        d[\"value\"] = item.find(\"span\",{\"class\":\"listing-price\"}).text.replace(\",\",\"\")\n",
    "    #   property description \n",
    "        d[\"desc\"] = (item.find(\"a\",{\"class\":\"main-link\"}).text).strip() \n",
    "    #   property size / bedroom capacity\n",
    "        try:\n",
    "             d[\"size\"] = item.find(\"span\",{\"class\":\"listing-attributes-value\"}).text.replace(\"\\n\",\"\")\n",
    "        except:\n",
    "            d[\"size\"] = None\n",
    "    #   property address\n",
    "        d[\"location\"] = item.find(\"p\",{\"class\":\"listing-address icon-location\"}).text\n",
    "    \n",
    "    #   collect data in a list\n",
    "        data.append(d)\n",
    "        \n",
    "    #   store data in a dataframe\n",
    "        df = pd.DataFrame(data)\n",
    "    #   save to csv\n",
    "        df.to_csv(\"scrapped_data/listing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to DataFrame for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('scrapped_data/listing.csv',\n",
    "                      usecols=['desc', 'location', 'size', 'value'])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save value as Numeric in Ksh\n",
    "df1['value'] = pd.to_numeric(df1['value'].str.replace(\"Contact seller for price|~|KSh| \",\"0\"))\n",
    "\n",
    "# Size to no of Bedrooms\n",
    "df1['size'] = df1['size'].str.split(' ').str[0]\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean dataset\n",
    "df1.to_csv('cleaned_data/NBO_listings_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.drop(562,axis=0,inplace=True)\n",
    "df1.shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
